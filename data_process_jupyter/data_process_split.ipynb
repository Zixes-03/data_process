{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mars.dataframe as md # https://pypi.org/project/pymars/\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"F:/Projects/Python/data_process/csv/tg_zd_machine-04.csv\"\n",
    "data_all = md.read_csv(data_path).to_pandas()\n",
    "data_all.index = pd.DatetimeIndex(data_all[\"UPDATE_DATE\"])\n",
    "data_all = data_all.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACHINE_ID</th>\n",
       "      <th>ONTIME</th>\n",
       "      <th>WORKTIME</th>\n",
       "      <th>STOPTIME</th>\n",
       "      <th>QTY</th>\n",
       "      <th>PASS_QTY</th>\n",
       "      <th>REJECTS_QTY</th>\n",
       "      <th>BEAT</th>\n",
       "      <th>EFFICIENCY</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>UPDATE_DATE</th>\n",
       "      <th>PDLINE_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPDATE_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-01 07:17:41</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/4/1 7:17:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01 07:18:05</th>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/4/1 7:18:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01 07:19:13</th>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/4/1 7:19:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01 07:19:17</th>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/4/1 7:19:17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01 07:19:30</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/4/1 7:19:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MACHINE_ID  ONTIME  WORKTIME  STOPTIME  QTY  PASS_QTY  \\\n",
       "UPDATE_DATE                                                                  \n",
       "2020-04-01 07:17:41          10      23         0        23    0       NaN   \n",
       "2020-04-01 07:18:05          10      47         0        47    0       NaN   \n",
       "2020-04-01 07:19:13          11      88         0        88    0       NaN   \n",
       "2020-04-01 07:19:17           3     146         0         0    0       NaN   \n",
       "2020-04-01 07:19:30          12       0         0         0    0       NaN   \n",
       "\n",
       "                     REJECTS_QTY  BEAT  EFFICIENCY  STATUS       UPDATE_DATE  \\\n",
       "UPDATE_DATE                                                                    \n",
       "2020-04-01 07:17:41          0.0   409         0.0       0  2020/4/1 7:17:41   \n",
       "2020-04-01 07:18:05          0.0   409         0.0       0  2020/4/1 7:18:05   \n",
       "2020-04-01 07:19:13          0.0    33         0.0       0  2020/4/1 7:19:13   \n",
       "2020-04-01 07:19:17          0.0   139         0.0       0  2020/4/1 7:19:17   \n",
       "2020-04-01 07:19:30          0.0  3809         0.0       0  2020/4/1 7:19:30   \n",
       "\n",
       "                     PDLINE_ID  \n",
       "UPDATE_DATE                     \n",
       "2020-04-01 07:17:41        NaN  \n",
       "2020-04-01 07:18:05        NaN  \n",
       "2020-04-01 07:19:13        NaN  \n",
       "2020-04-01 07:19:17        NaN  \n",
       "2020-04-01 07:19:30        NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5537184"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总数据大小\n",
    "data_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of assembly line data:3069551\n",
      "length of checking line data:2467633\n"
     ]
    }
   ],
   "source": [
    "# 拆分装配线以及检测线\n",
    "data_assembly = data_all.loc[data_all.PDLINE_ID.notnull()]\n",
    "data_checking = data_all.loc[data_all.PDLINE_ID.isnull()]\n",
    "print(\"length of assembly line data:{0}\".format(data_assembly.shape[0]))\n",
    "print(\"length of checking line data:{0}\".format(data_checking.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据输出.csv\n",
    "def split_csv(data_csv):\n",
    "    if(2 in data_csv[\"PDLINE_ID\"].values.tolist()):\n",
    "        for i in range(1,13):\n",
    "            output = data_csv[data_csv[\"MACHINE_ID\"].isin([i])]\n",
    "            output.to_csv('F:/Projects/Python/data_process/csv/splited_data/data_assembly_{0}.csv'.format(i),\n",
    "                          index=None)\n",
    "    else:\n",
    "        for i in range(1,13):\n",
    "            output = data_csv[data_csv[\"MACHINE_ID\"].isin([i])]\n",
    "            output.to_csv('F:/Projects/Python/data_process/csv/splited_data/data_checking_{0}.csv'.format(i),\n",
    "                          index=None)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出.csv别手贱运行！\n",
    "# split_csv(data_assembly)\n",
    "# split_csv(data_checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data_assembly_1.csv: 4389.\n",
      "The length of data_assembly_10.csv: 303791.\n",
      "The length of data_assembly_11.csv: 303961.\n",
      "The length of data_assembly_12.csv: 313935.\n",
      "The length of data_assembly_2.csv: 304524.\n",
      "The length of data_assembly_3.csv: 307289.\n",
      "The length of data_assembly_4.csv: 304287.\n",
      "The length of data_assembly_5.csv: 4656.\n",
      "The length of data_assembly_6.csv: 308159.\n",
      "The length of data_assembly_7.csv: 303956.\n",
      "The length of data_assembly_8.csv: 304361.\n",
      "The length of data_assembly_9.csv: 306243.\n",
      "The length of data_checking_1.csv: 322915.\n",
      "The length of data_checking_10.csv: 263207.\n",
      "The length of data_checking_11.csv: 344964.\n",
      "The length of data_checking_12.csv: 322976.\n",
      "The length of data_checking_2.csv: 349780.\n",
      "The length of data_checking_3.csv: 268791.\n",
      "The length of data_checking_4.csv: 1365.\n",
      "The length of data_checking_5.csv: 292293.\n",
      "The length of data_checking_6.csv: 0.\n",
      "The length of data_checking_7.csv: 269611.\n",
      "The length of data_checking_8.csv: 18670.\n",
      "The length of data_checking_9.csv: 13061.\n"
     ]
    }
   ],
   "source": [
    "# 批量输入拆分后的数据\n",
    "file_dir = 'F:/Projects/Python/data_process/csv/splited_data'\n",
    "file_list = []\n",
    "data_dict = {}\n",
    "for root, dirs, files in os.walk(file_dir):  \n",
    "    for file in files:  \n",
    "            if os.path.splitext(file)[1] == '.csv':  \n",
    "                file_list.append(file)\n",
    "\n",
    "for file in file_list:\n",
    "    data_in = md.read_csv('F:/Projects/Python/data_process/csv/splited_data/{0}'.format(file)).to_pandas()\n",
    "    data_in.index = pd.DatetimeIndex(data_in[\"UPDATE_DATE\"])\n",
    "    print(\"The length of {0}: {1}.\".format(file,data_in.shape[0]))\n",
    "    data_dict[\"{0}\".format(file)] = data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 丢弃工作时间错误的数据\n",
    "def process_error_data_01(data):   \n",
    "    for index, row in data.iterrows():\n",
    "        if row['ONTIME'] != row['WORKTIME'] + row['STOPTIME']:\n",
    "#             print(index, row['MACHINE_ID'] ,row['PDLINE_ID'])\n",
    "            data.drop(index = index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time 214.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 单核处理\n",
    "start = time.time()\n",
    "process_error_data_01(data_tianzheng_assembly)\n",
    "end = time.time()\n",
    "print('Processing time %0.2f seconds.' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到文件中的日期\n",
    "# https://www.cnblogs.com/nxf-rabbit75/p/10662025.html\n",
    "def get_date_list(data):\n",
    "    process_data = data.copy()\n",
    "    process_data = process_data.resample('D').mean()\n",
    "    process_data = process_data.dropna(axis=0,how=\"all\")\n",
    "    process_date_list = process_data.index.strftime('%Y-%m-%d').tolist() # https://www.runoob.com/python/att-time-strftime.html\n",
    "\n",
    "    #  用完删除，释放内存\n",
    "    del process_data\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    return process_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断后一天开始时的QTY是否清零，即是否小于前一天结束时的QTY\n",
    "def process_error_data_02(data, date_list):\n",
    "    error = False\n",
    "    for i in range(len(date_list)-1):\n",
    "        QTY_01 = int(data.loc[date_list[i]][-1:]['QTY'])\n",
    "        QTY_02 = int(data.loc[date_list[i+1]][:1]['QTY'])        \n",
    "        if QTY_02 >= QTY_01:\n",
    "#             判断开始结束的时间先后，思路错误，不需要判断\n",
    "#             d1 = data.loc[date_list[i]][-1:].index.strftime(\"%H/%M/%S\").values[0]\n",
    "#             d2 = data.loc[date_list[i+1]][:1].index.strftime(\"%H/%M/%S\").values[0]\n",
    "#             d1 = datetime.strptime(d1, \"%H/%M/%S\")\n",
    "#             d2 = datetime.strptime(d2, \"%H/%M/%S\")\n",
    "#             if d2 > d1:\n",
    "            print(\"* QTY of the day before:\\n\",data.loc[date_list[i]][-1:][['QTY']],'\\n')\n",
    "            print(\"* QTY of the day after:\\n\",data.loc[date_list[i+1]][:1][['QTY']],'\\n')\n",
    "            error = True\n",
    "    if error == False:\n",
    "        print(\"QTY data are all correct!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********data_assembly_1.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_assembly_10.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:45:24  3910 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:00  5227 \n",
      "\n",
      "**********data_assembly_11.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:45:26  3903 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:00  5217 \n",
      "\n",
      "**********data_assembly_12.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 13:45:16  4551 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:00  5205 \n",
      "\n",
      "**********data_assembly_2.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:52:18  4396 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:04  4977 \n",
      "\n",
      "**********data_assembly_3.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_assembly_4.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:52:21  4373 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:07  4942 \n",
      "\n",
      "**********data_assembly_5.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_assembly_6.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_assembly_7.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:52:21  4046 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:00  5239 \n",
      "\n",
      "**********data_assembly_8.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 12:52:17  4034 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:00  5217 \n",
      "\n",
      "**********data_assembly_9.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-01 13:55:15  4756 \n",
      "\n",
      "* QTY of the day after:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-16 13:21:02  5237 \n",
      "\n",
      "**********data_checking_1.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_10.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_11.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_12.csv**********\n",
      "* QTY of the day before:\n",
      "                        QTY\n",
      "UPDATE_DATE               \n",
      "2020-04-26 16:18:14  20440 \n",
      "\n",
      "* QTY of the day after:\n",
      "                        QTY\n",
      "UPDATE_DATE               \n",
      "2020-04-27 07:17:35  20440 \n",
      "\n",
      "**********data_checking_2.csv**********\n",
      "* QTY of the day before:\n",
      "                       QTY\n",
      "UPDATE_DATE              \n",
      "2020-04-18 19:26:07  2880 \n",
      "\n",
      "* QTY of the day after:\n",
      "                        QTY\n",
      "UPDATE_DATE               \n",
      "2020-04-20 13:47:09  14417 \n",
      "\n",
      "**********data_checking_3.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_4.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_5.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_6.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_7.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_8.csv**********\n",
      "QTY data are all correct!\n",
      "\n",
      "**********data_checking_9.csv**********\n",
      "QTY data are all correct!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data_dict:\n",
    "    print(\"**********\"+ key + \"**********\")\n",
    "    process_error_data_02(data_dict[key], get_date_list(data_dict[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
